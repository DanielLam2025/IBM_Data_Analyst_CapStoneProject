{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collecting Job Data Using APIs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Collect job data using Jobs API\n",
    "*   Store the collected data into an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><strong>Note: Before starting with the assignment make sure to read all the instructions and then move ahead with the coding part.</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the actual lab, firstly you need to click on the [Jobs_API](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Jobs_API.ipynb) notebook link. The file contains flask code which is required to run the Jobs API data.\n",
    "\n",
    "Now, to run the code in the file that opens up follow the below steps.\n",
    "\n",
    "Step1: Download the file. \n",
    "\n",
    "Step2: Upload the file into your current Jupyter environment using the upload button in your Jupyter interface. Ensure that the file is in the same folder as your working .ipynb file.\n",
    "\n",
    "Step 2: If working in a local Jupyter environment, use the \"Upload\" button in your Jupyter interface to upload the Jobs_API notebook into the same folder as your current .ipynb file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Upload.PNG\">\n",
    "\n",
    "Step3:  Open the Jobs_API notebook, and run all the cells to start the Flask application. Once the server is running, you can access the API from the URL provided in the notebook.\n",
    "\n",
    "If you want to learn more about flask, which is optional, you can click on this link [here](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/FLASK_API.md.html).\n",
    "\n",
    "Once you run the flask code, you can start with your assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Used in this Assignment\n",
    "\n",
    "The dataset used in this lab comes from the following source: https://www.kaggle.com/promptcloud/jobs-on-naukricom under the under a **Public Domain license**.\n",
    "\n",
    "> Note: We are using a modified subset of that dataset for the lab, so to follow the lab instructions successfully please use the dataset provided with the lab, rather than the dataset from the original source.\n",
    "\n",
    "The original dataset is a csv. We have converted the csv to json as per the requirement of the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you attempt the actual lab, here is a fully solved warmup exercise that will help you to learn how to access an API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an API, let us find out who currently are on the International Space Station (ISS).<br> The API at [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ) gives us the information of astronauts currently on ISS in json format.<br>\n",
    "You can read more about this API at [http://open-notify.org/Open-Notify-API/People-In-Space/](http://open-notify.org/Open-Notify-API/People-In-Space?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests # you need this module to make an API call\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_url = \"http://api.open-notify.org/astros.json\" # this url gives use the astronaut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(api_url) # Call the API using the get method and store the\n",
    "                                # output of the API call in a variable called response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if response.ok:             # if all is well() no errors, no network timeouts)\n",
    "    data = response.json()  # store the result in json format in a variable called data\n",
    "                            # the variable data is of type dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'}, {'craft': 'ISS', 'name': 'Nikolai Chub'}, {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'}, {'craft': 'ISS', 'name': 'Matthew Dominick'}, {'craft': 'ISS', 'name': 'Michael Barratt'}, {'craft': 'ISS', 'name': 'Jeanette Epps'}, {'craft': 'ISS', 'name': 'Alexander Grebenkin'}, {'craft': 'ISS', 'name': 'Butch Wilmore'}, {'craft': 'ISS', 'name': 'Sunita Williams'}, {'craft': 'Tiangong', 'name': 'Li Guangsu'}, {'craft': 'Tiangong', 'name': 'Li Cong'}, {'craft': 'Tiangong', 'name': 'Ye Guangfu'}], 'number': 12, 'message': 'success'}\n"
     ]
    }
   ],
   "source": [
    "print(data)   # print the data just to check the output or for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(data.get('number'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the names of the astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 astronauts on ISS\n",
      "And their names are :\n",
      "Oleg Kononenko\n",
      "Nikolai Chub\n",
      "Tracy Caldwell Dyson\n",
      "Matthew Dominick\n",
      "Michael Barratt\n",
      "Jeanette Epps\n",
      "Alexander Grebenkin\n",
      "Butch Wilmore\n",
      "Sunita Williams\n",
      "Li Guangsu\n",
      "Li Cong\n",
      "Ye Guangfu\n"
     ]
    }
   ],
   "source": [
    "astronauts = data.get('people')\n",
    "print(\"There are {} astronauts on ISS\".format(len(astronauts)))\n",
    "print(\"And their names are :\")\n",
    "for astronaut in astronauts:\n",
    "    print(astronaut.get('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope the warmup was helpful. Good luck with your next lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Collect Jobs Data using Jobs API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Determine the number of jobs currently open for various technologies  and for various locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following locations using the API:\n",
    "\n",
    "* Los Angeles\n",
    "* New York\n",
    "* San Francisco\n",
    "* Washington DC\n",
    "* Seattle\n",
    "* Austin\n",
    "* Detroit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json#### Write a function to get the number of jobs for the Python technology.<br>\n",
    "> Note: While using the lab you need to pass the **payload** information for the **params** attribute in the form of **key** **value** pairs.\n",
    "  Refer the ungraded **rest api lab** in the course **Python for Data Science, AI & Development**  <a href=\"https://www.coursera.org/learn/python-for-applied-data-science-ai/ungradedLti/P6sW8/hands-on-lab-access-rest-apis-request-http?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\">link</a>\n",
    "  \n",
    " ##### The keys in the json are \n",
    " * Job Title\n",
    " \n",
    " * Job Experience Required\n",
    " \n",
    " * Key Skills\n",
    " \n",
    " * Role Category\n",
    " \n",
    " * Location\n",
    " \n",
    " * Functional Area\n",
    " \n",
    " * Industry\n",
    " \n",
    " * Role \n",
    " \n",
    "You can also view  the json file contents  from the following <a href = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\">json</a> URL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_T(technology):\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        jobs_data = response.json()\n",
    "        technology_lower = technology.lower()\n",
    "        \n",
    "        number_of_jobs = 0\n",
    "        for job in jobs_data:\n",
    "            if 'Key Skills' in job and technology_lower in job['Key Skills'].lower():\n",
    "                number_of_jobs += 1\n",
    "                \n",
    "        return technology, number_of_jobs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return technology, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function for Python and checking if it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Python', 1173)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_jobs_T(\"Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to find number of jobs in US for a location of your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs by location:\n",
      "==============================\n",
      "Los Angeles    : 640 jobs\n",
      "New York       : 3226 jobs\n",
      "San Francisco  : 435 jobs\n",
      "Washington DC  : 5316 jobs\n",
      "Seattle        : 3375 jobs\n",
      "Austin         : 434 jobs\n",
      "Detroit        : 3945 jobs\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_L(location):\n",
    "    \"\"\"\n",
    "    Get the number of job postings for a specific location in the US\n",
    "    \n",
    "    Parameters:\n",
    "    location (str): The location to search for (e.g., 'Los Angeles', 'New York')\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (location, number_of_jobs)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the data from the API\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the JSON data\n",
    "        jobs_data = response.json()\n",
    "        \n",
    "        # Convert to DataFrame for easier processing\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        \n",
    "        # Count jobs that match the location (case-insensitive)\n",
    "        # The location is in the 'Location' field of the JSON\n",
    "        number_of_jobs = df['Location'].str.lower().str.contains(location.lower()).sum()\n",
    "        \n",
    "        return location, number_of_jobs\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return location, 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return location, 0\n",
    "\n",
    "# Test the function for the locations mentioned in the lab\n",
    "locations = [\n",
    "    \"Los Angeles\", \n",
    "    \"New York\", \n",
    "    \"San Francisco\", \n",
    "    \"Washington DC\", \n",
    "    \"Seattle\", \n",
    "    \"Austin\", \n",
    "    \"Detroit\"\n",
    "]\n",
    "\n",
    "print(\"Number of jobs by location:\")\n",
    "print(\"=\" * 30)\n",
    "for location in locations:\n",
    "    loc, count = get_number_of_jobs_L(location)\n",
    "    print(f\"{loc:<15}: {count} jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function for Los Angeles and check if it is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing function for Los Angeles:\n",
      "==============================\n",
      "Location: Los Angeles\n",
      "Number of jobs: 640\n",
      "\n",
      "Function return type: <class 'tuple'>\n",
      "Location data type: <class 'str'>\n",
      "Count data type: <class 'numpy.int64'>\n",
      "Count is non-negative: True\n",
      "✓ Function is working - found job postings in Los Angeles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_L(location):\n",
    "    \"\"\"\n",
    "    Get the number of job postings for a specific location in the US\n",
    "    \n",
    "    Parameters:\n",
    "    location (str): The location to search for (e.g., 'Los Angeles', 'New York')\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (location, number_of_jobs)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the data from the API\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the JSON data\n",
    "        jobs_data = response.json()\n",
    "        \n",
    "        # Convert to DataFrame for easier processing\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        \n",
    "        # Count jobs that match the location (case-insensitive)\n",
    "        # The location is in the 'Location' field of the JSON\n",
    "        number_of_jobs = df['Location'].str.lower().str.contains(location.lower()).sum()\n",
    "        \n",
    "        return location, number_of_jobs\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return location, 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return location, 0\n",
    "\n",
    "# Test the function specifically for Los Angeles\n",
    "print(\"Testing function for Los Angeles:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "location, count = get_number_of_jobs_L(\"Los Angeles\")\n",
    "print(f\"Location: {location}\")\n",
    "print(f\"Number of jobs: {count}\")\n",
    "\n",
    "# Verify the function is working by checking the data type and values\n",
    "print(f\"\\nFunction return type: {type((location, count))}\")\n",
    "print(f\"Location data type: {type(location)}\")\n",
    "print(f\"Count data type: {type(count)}\")\n",
    "print(f\"Count is non-negative: {count >= 0}\")\n",
    "\n",
    "# Additional test to make sure it's working correctly\n",
    "if count > 0:\n",
    "    print(\"✓ Function is working - found job postings in Los Angeles\")\n",
    "else:\n",
    "    print(\"⚠ No job postings found for Los Angeles (this could be normal if no jobs exist for this location)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results in an excel file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API for all the given technologies above and write the results in an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.3-py2.py3-none-any.whl (251 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.3\n",
      "Python: 1173 jobs\n",
      "Java: 3428 jobs\n",
      "JavaScript: 2248 jobs\n",
      "SQL: 3221 jobs\n",
      "AWS: 346 jobs\n",
      "Azure: 170 jobs\n",
      "Docker: 102 jobs\n",
      "Kubernetes: 4 jobs\n",
      "React: 187 jobs\n",
      "Node.js: 215 jobs\n",
      "\n",
      "Excel file 'technology_job_counts.xlsx' created successfully!\n",
      "   Technology  Number of Jobs\n",
      "0      Python            1173\n",
      "1        Java            3428\n",
      "2  JavaScript            2248\n",
      "3         SQL            3221\n",
      "4         AWS             346\n",
      "5       Azure             170\n",
      "6      Docker             102\n",
      "7  Kubernetes               4\n",
      "8       React             187\n",
      "9     Node.js             215\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_T(technology):\n",
    "    \"\"\"\n",
    "    Get the number of job postings for a specific technology\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        jobs_data = response.json()\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        number_of_jobs = df['Key Skills'].str.lower().str.contains(technology.lower()).sum()\n",
    "        \n",
    "        return technology, number_of_jobs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return technology, 0\n",
    "\n",
    "# List of technologies to analyze\n",
    "technologies = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"SQL\", \"AWS\", \n",
    "    \"Azure\", \"Docker\", \"Kubernetes\", \"React\", \"Node.js\"\n",
    "]\n",
    "\n",
    "# Create a list to store results\n",
    "results = []\n",
    "\n",
    "# Get job counts for each technology\n",
    "for tech in technologies:\n",
    "    technology, count = get_number_of_jobs_T(tech)\n",
    "    results.append({\"Technology\": technology, \"Number of Jobs\": count})\n",
    "    print(f\"{technology}: {count} jobs\")\n",
    "\n",
    "# Create DataFrame and save to Excel\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"technology_job_counts.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nExcel file 'technology_job_counts.xlsx' created successfully!\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python list of all technologies for which you need to find the number of jobs postings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technologies to analyze: ['Python', 'Java', 'JavaScript', 'SQL', 'AWS', 'Azure', 'Docker', 'Kubernetes', 'React', 'Node.js', 'Machine Learning', 'Data Science', 'Tableau', 'Spark', 'Hadoop']\n",
      "Number of technologies: 15\n"
     ]
    }
   ],
   "source": [
    "# Create a python list of all technologies for which you need to find the number of jobs postings.\n",
    "technologies = [\n",
    "    \"Python\",\n",
    "    \"Java\", \n",
    "    \"JavaScript\",\n",
    "    \"SQL\",\n",
    "    \"AWS\",\n",
    "    \"Azure\",\n",
    "    \"Docker\",\n",
    "    \"Kubernetes\",\n",
    "    \"React\",\n",
    "    \"Node.js\",\n",
    "    \"Machine Learning\",\n",
    "    \"Data Science\",\n",
    "    \"Tableau\",\n",
    "    \"Spark\", \n",
    "    \"Hadoop\"\n",
    "]\n",
    "\n",
    "print(\"Technologies to analyze:\", technologies)\n",
    "print(\"Number of technologies:\", len(technologies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries required to create excel spreadsheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openpyxl is already installed\n",
      "All required libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# First, install openpyxl if not already installed\n",
    "try:\n",
    "    import openpyxl\n",
    "    print(\"openpyxl is already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing openpyxl...\")\n",
    "    !pip install openpyxl\n",
    "    import openpyxl\n",
    "    print(\"openpyxl installed successfully\")\n",
    "\n",
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import requests\n",
    "import json\n",
    "\n",
    "print(\"All required libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a workbook and select the active worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workbook created successfully!\n",
      "Active worksheet: 'Job Analysis Results'\n",
      "Number of worksheets: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a workbook and select the active worksheet\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Create a new workbook object\n",
    "wb = Workbook()\n",
    "\n",
    "# Select the active worksheet (default is the first sheet)\n",
    "ws = wb.active\n",
    "\n",
    "# You can also rename the active worksheet\n",
    "ws.title = \"Job Analysis Results\"\n",
    "\n",
    "print(\"Workbook created successfully!\")\n",
    "print(f\"Active worksheet: '{ws.title}'\")\n",
    "print(f\"Number of worksheets: {len(wb.worksheets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of jobs postings for each of the technology in the above list.\n",
    "Write the technology name and the number of jobs postings into the excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching job postings for each technology...\n",
      "==================================================\n",
      "Python              : 1173 jobs\n",
      "Java                : 3428 jobs\n",
      "JavaScript          : 2248 jobs\n",
      "SQL                 : 3221 jobs\n",
      "AWS                 : 346 jobs\n",
      "Azure               : 170 jobs\n",
      "Docker              : 102 jobs\n",
      "Kubernetes          : 4 jobs\n",
      "React               : 187 jobs\n",
      "Node.js             : 215 jobs\n",
      "Machine Learning    : 243 jobs\n",
      "Data Science        : 89 jobs\n",
      "Tableau             : 69 jobs\n",
      "Spark               : 105 jobs\n",
      "Hadoop              : 122 jobs\n",
      "==================================================\n",
      "✓ Results saved to 'technology_job_postings.xlsx' successfully!\n",
      "✓ Total technologies processed: 15\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# List of technologies to analyze\n",
    "technologies = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"SQL\", \"AWS\",\n",
    "    \"Azure\", \"Docker\", \"Kubernetes\", \"React\", \"Node.js\",\n",
    "    \"Machine Learning\", \"Data Science\", \"Tableau\", \"Spark\", \"Hadoop\"\n",
    "]\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "def get_number_of_jobs_T(technology):\n",
    "    \"\"\"\n",
    "    Get the number of job postings for a specific technology\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        jobs_data = response.json()\n",
    "        df = pd.DataFrame(jobs_data)\n",
    "        number_of_jobs = df['Key Skills'].str.lower().str.contains(technology.lower()).sum()\n",
    "        return technology, number_of_jobs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {technology}: {e}\")\n",
    "        return technology, 0\n",
    "\n",
    "# Create workbook and select active worksheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Technology Job Counts\"\n",
    "\n",
    "# Add headers to the worksheet\n",
    "ws.append(['Technology', 'Number of Jobs Postings'])\n",
    "\n",
    "print(\"Fetching job postings for each technology...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get job counts for each technology and write to Excel\n",
    "for technology in technologies:\n",
    "    tech_name, job_count = get_number_of_jobs_T(technology)\n",
    "    ws.append([tech_name, job_count])\n",
    "    print(f\"{tech_name:<20}: {job_count} jobs\")\n",
    "\n",
    "# Save the workbook\n",
    "filename = \"technology_job_postings.xlsx\"\n",
    "wb.save(filename)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"✓ Results saved to '{filename}' successfully!\")\n",
    "print(f\"✓ Total technologies processed: {len(technologies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save into an excel spreadsheet named **job-postings.xlsx**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching job data from API...\n",
      "Data fetched successfully!\n",
      "\n",
      "Processing job postings for each technology:\n",
      "=============================================\n",
      "Python              : 1173 jobs\n",
      "Java                : 3428 jobs\n",
      "JavaScript          : 2248 jobs\n",
      "SQL                 : 3221 jobs\n",
      "AWS                 : 346 jobs\n",
      "Azure               : 170 jobs\n",
      "Docker              : 102 jobs\n",
      "Kubernetes          : 4 jobs\n",
      "React               : 187 jobs\n",
      "Node.js             : 215 jobs\n",
      "Machine Learning    : 243 jobs\n",
      "Data Science        : 89 jobs\n",
      "Tableau             : 69 jobs\n",
      "Spark               : 105 jobs\n",
      "Hadoop              : 122 jobs\n",
      "=============================================\n",
      "✓ Excel spreadsheet saved as 'job-postings.xlsx'\n",
      "✓ Contains job posting data for 15 technologies\n",
      "✓ File is ready for use!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# List of technologies to analyze\n",
    "technologies = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"SQL\", \"AWS\",\n",
    "    \"Azure\", \"Docker\", \"Kubernetes\", \"React\", \"Node.js\",\n",
    "    \"Machine Learning\", \"Data Science\", \"Tableau\", \"Spark\", \"Hadoop\"\n",
    "]\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "# Fetch data from API\n",
    "print(\"Fetching job data from API...\")\n",
    "response = requests.get(api_url)\n",
    "jobs_data = response.json()\n",
    "df = pd.DataFrame(jobs_data)\n",
    "print(\"Data fetched successfully!\")\n",
    "\n",
    "# Create workbook and worksheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Job Postings Analysis\"\n",
    "\n",
    "# Add headers with formatting\n",
    "headers = ['Technology', 'Number of Jobs Postings']\n",
    "ws.append(headers)\n",
    "\n",
    "# Format header row\n",
    "header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "\n",
    "for col in range(1, 3):\n",
    "    cell = ws.cell(row=1, column=col)\n",
    "    cell.font = header_font\n",
    "    cell.fill = header_fill\n",
    "\n",
    "print(\"\\nProcessing job postings for each technology:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Get job counts for each technology and write to Excel\n",
    "for technology in technologies:\n",
    "    job_count = df['Key Skills'].str.lower().str.contains(technology.lower()).sum()\n",
    "    ws.append([technology, job_count])\n",
    "    print(f\"{technology:<20}: {job_count} jobs\")\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for column in ws.columns:\n",
    "    max_length = 0\n",
    "    column_letter = column[0].column_letter\n",
    "    for cell in column:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = min(max_length + 2, 50)  # Cap width at 50\n",
    "    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# Save the workbook with the specified filename\n",
    "filename = \"job-postings.xlsx\"\n",
    "wb.save(filename)\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(f\"✓ Excel spreadsheet saved as '{filename}'\")\n",
    "print(f\"✓ Contains job posting data for {len(technologies)} technologies\")\n",
    "print(\"✓ File is ready for use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the similar way, you can try for below given technologies and results  can be stored in an excel sheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following languages using the API:\n",
    "\n",
    "*   C\n",
    "*   C#\n",
    "*   C++\n",
    "*   Java\n",
    "*   JavaScript\n",
    "*   Python\n",
    "*   Scala\n",
    "*   Oracle\n",
    "*   SQL Server\n",
    "*   MySQL Server\n",
    "*   PostgreSQL\n",
    "*   MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching job data from API...\n",
      "Data fetched successfully!\n",
      "\n",
      "Processing job postings for each language/database:\n",
      "=======================================================\n",
      "C              : 1655 jobs\n",
      "C#             : 0 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++            : 0 jobs\n",
      "Java           : 1601 jobs\n",
      "JavaScript     : 2246 jobs\n",
      "Python         : 1171 jobs\n",
      "Scala          : 89 jobs\n",
      "Oracle         : 899 jobs\n",
      "SQL Server     : 422 jobs\n",
      "MySQL Server   : 0 jobs\n",
      "PostgreSQL     : 86 jobs\n",
      "MongoDB        : 208 jobs\n",
      "=======================================================\n",
      "✓ Excel spreadsheet saved as 'language-database-job-postings.xlsx'\n",
      "✓ Contains job posting data for 12 languages/databases\n",
      "✓ File is ready for use!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# List of languages and databases to analyze\n",
    "technologies = [\n",
    "    \"C\",\n",
    "    \"C#\", \n",
    "    \"C++\",\n",
    "    \"Java\",\n",
    "    \"JavaScript\",\n",
    "    \"Python\",\n",
    "    \"Scala\",\n",
    "    \"Oracle\",\n",
    "    \"SQL Server\",\n",
    "    \"MySQL Server\",\n",
    "    \"PostgreSQL\",\n",
    "    \"MongoDB\"\n",
    "]\n",
    "\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "# Fetch data from API\n",
    "print(\"Fetching job data from API...\")\n",
    "response = requests.get(api_url)\n",
    "jobs_data = response.json()\n",
    "df = pd.DataFrame(jobs_data)\n",
    "print(\"Data fetched successfully!\")\n",
    "\n",
    "# Create workbook and worksheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Language & Database Job Postings\"\n",
    "\n",
    "# Add headers with formatting\n",
    "headers = ['Technology', 'Number of Jobs Postings']\n",
    "ws.append(headers)\n",
    "\n",
    "# Format header row\n",
    "header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "\n",
    "for col in range(1, 3):\n",
    "    cell = ws.cell(row=1, column=col)\n",
    "    cell.font = header_font\n",
    "    cell.fill = header_fill\n",
    "\n",
    "print(\"\\nProcessing job postings for each language/database:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Get job counts for each technology and write to Excel\n",
    "for technology in technologies:\n",
    "    # Special handling for C# and C++ to avoid false matches\n",
    "    if technology == \"C#\":\n",
    "        # Look for C# specifically (not just \"C\")\n",
    "        pattern = r'\\bC#\\b'\n",
    "        job_count = df['Key Skills'].str.contains(pattern, case=False, na=False).sum()\n",
    "    elif technology == \"C++\":\n",
    "        # Look for C++ specifically\n",
    "        pattern = r'\\bC\\+\\+\\b'\n",
    "        job_count = df['Key Skills'].str.contains(pattern, case=False, na=False).sum()\n",
    "    elif technology == \"SQL Server\":\n",
    "        # Look for SQL Server specifically\n",
    "        pattern = r'\\bSQL Server\\b'\n",
    "        job_count = df['Key Skills'].str.contains(pattern, case=False, na=False).sum()\n",
    "    elif technology == \"MySQL Server\":\n",
    "        # Look for MySQL Server specifically\n",
    "        pattern = r'\\bMySQL Server\\b'\n",
    "        job_count = df['Key Skills'].str.contains(pattern, case=False, na=False).sum()\n",
    "    else:\n",
    "        # For other technologies, use simple contains with word boundaries\n",
    "        job_count = df['Key Skills'].str.lower().str.contains(r'\\b' + technology.lower() + r'\\b').sum()\n",
    "    \n",
    "    ws.append([technology, job_count])\n",
    "    print(f\"{technology:<15}: {job_count} jobs\")\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for column in ws.columns:\n",
    "    max_length = 0\n",
    "    column_letter = column[0].column_letter\n",
    "    for cell in column:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = min(max_length + 2, 50)\n",
    "    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# Save the workbook\n",
    "filename = \"language-database-job-postings.xlsx\"\n",
    "wb.save(filename)\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(f\"✓ Excel spreadsheet saved as '{filename}'\")\n",
    "print(f\"✓ Contains job posting data for {len(technologies)} languages/databases\")\n",
    "print(\"✓ File is ready for use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayushi Jain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n",
    "\n",
    "Lakshmi Holla\n",
    "\n",
    "Malika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- | \n",
    "| 2022-01-19        | 0.3     | Lakshmi Holla        | Added changes in the markdown      |\n",
    "| 2021-06-25        | 0.2     | Malika            | Updated GitHub job json link       |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "61a35a07ad98492b710274ae0e52a0fdce2221e88e366133dd4a20370680fa8f"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
